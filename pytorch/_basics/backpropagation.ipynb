{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce828a1",
   "metadata": {},
   "source": [
    "## **Differentiation in Autograd**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace29cb",
   "metadata": {},
   "source": [
    "**Backpropagation:** Parameters are adjusted according to the gradient of the loss function.\n",
    "\n",
    "`torch.autograd`: Differentiation Engine. Gradients are calculated using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675a1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7c8e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# input tensor\n",
    "\n",
    "x = torch.ones(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c08f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# output tensor\n",
    "\n",
    "y = torch.zeros(3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f51c2",
   "metadata": {},
   "source": [
    "In the bellow variables `w` and `b` are parameters which we need to optimize. Therefore, setting `requires_grad` attribute as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeb02e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5493,  0.0203,  0.1157],\n",
      "        [-0.7170,  0.2039,  1.6857],\n",
      "        [ 0.8402,  0.7463,  1.8053],\n",
      "        [-1.3074, -0.0734,  0.7490],\n",
      "        [-0.2875, -0.8547,  1.3091]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# randomly specifying weight value\n",
    "\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d4e650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6305,  0.2254, -0.5351], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# randomly speifying bias value\n",
    "\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f9dcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.6515,  0.2677,  5.1298], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276b3a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0133, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    }
   ],
   "source": [
    "# calculating loass\n",
    "\n",
    "loss = nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeaec96",
   "metadata": {},
   "source": [
    "`grad_fn`: Reference to backward propagation is stored here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81a0fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x000002A20B95E308>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward object at 0x000002A20B95E2C8>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =',z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774dcf94",
   "metadata": {},
   "source": [
    "#### **Computing Gradients**\n",
    "\n",
    "`backward()`: to compute the derivative\n",
    "\n",
    "`grad`: gradients are retrived using it. Only calculated when requires_grad value is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae9c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0220, 0.1888, 0.3314],\n",
      "        [0.0220, 0.1888, 0.3314],\n",
      "        [0.0220, 0.1888, 0.3314],\n",
      "        [0.0220, 0.1888, 0.3314],\n",
      "        [0.0220, 0.1888, 0.3314]])\n",
      "tensor([0.0220, 0.1888, 0.3314])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cced27",
   "metadata": {},
   "source": [
    "#### **Disabling Gradient Tracking**\n",
    "\n",
    "Done using `no_grad()` or `detach()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8372c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe7ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9dffd",
   "metadata": {},
   "source": [
    "### **Tensor Gradients and Jacobian Products**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b0fa4",
   "metadata": {},
   "source": [
    "In this demonstration we will find that all the gradients value are stored in the last node of graph. To find again the previous value gradient has to be set zero using-- `grad.zero_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56eb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f990c7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a375c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35497d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0409e7",
   "metadata": {},
   "source": [
    "### **Another Iteration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40382481",
   "metadata": {},
   "source": [
    "`a` and `b` are two tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45fdb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3494718e",
   "metadata": {},
   "source": [
    "Creating tensor `Q` from tensor `a` and `b`\n",
    "\n",
    "> Q=3a<sup>3</sup> - b<sup>2</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96fc9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47dc11a",
   "metadata": {},
   "source": [
    "Here, `a` and `b` are parameters and `Q` is error\n",
    "\n",
    "    * When `Q.backward()` (It is a vector) is called autograd calculates gradiants and stores them.\n",
    "    * It store value in `gradiants` ------- It is tensor of same shape as `Q`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4060d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd245c6a",
   "metadata": {},
   "source": [
    "Checking gradiants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af89822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce516f4",
   "metadata": {},
   "source": [
    "#### **Exclusion from the DAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1b2c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730b9d1",
   "metadata": {},
   "source": [
    "Gradients of all parameters in model are set as False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "710cb604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\91939/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df833274011443c1a07771a4209642c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8e378",
   "metadata": {},
   "source": [
    "All layers are frozen expect parameters of last layer -----> Gradients are computed using weights and bias of last layer- `model.fc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a74b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize only the classifier\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
